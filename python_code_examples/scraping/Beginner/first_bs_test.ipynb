{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://weimergeeks.com/examples/scraping/example1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>We Are Learning About Web Scraping!</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "# copy the entire contents of the URL given into a new Python variable\n",
    "page = urlopen(\"https://weimergeeks.com/examples/scraping/example1.html\") \n",
    "# process the value of that variable (the plain-text contents) through a built-in HTML parser called html.parser.\n",
    "soup = BeautifulSoup(page, \"html.parser\") \n",
    "print(soup.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Are Learning About Web Scraping!\n"
     ]
    }
   ],
   "source": [
    "heading = soup.h1\n",
    "print(heading.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some basic BeautifulSoup commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding elements that have a particular class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = soup.find_all( \"td\", class_=\"city\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ATTENTION:  \n",
    " Using class (alone) in the code above would give you a syntax error. So when we search by CSS class with BeautifulSoup, we use the keyword argument class_ — note the added underscore. Other HTML attributes DO NOT need the underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oslo\n",
      "Guanajuato\n",
      "San Juan\n",
      "Matera\n",
      "Antwerp\n",
      "Kaohsiung\n",
      "Hamburg\n",
      "Canberra\n",
      "Detroit\n",
      "Seville\n"
     ]
    }
   ],
   "source": [
    "for city in city_list:\n",
    "    print( city.get_text() )\n",
    "    # Equal to city.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all vs. finding one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BeautifulSoup find_all() method you just saw always produces a list. \n",
    "(Note: findAll() will also work.) \n",
    "\n",
    "If you know there will be only one item of the kind you want in a file, you should use the find() method instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, maybe you are scraping the address and phone number from every page in a large website. \n",
    "\n",
    "On the page we are currently using, there is only one phone number, and it is enclosed in a pair of tags with the attribute id=\"call\". \n",
    "\n",
    "One line of your code gets the phone number from the current page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 (352) 555-4321\n"
     ]
    }
   ],
   "source": [
    "phone_number = soup.find(id=\"call\")\n",
    "print( phone_number.text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the contents of a particular attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you’ve made a BeautifulSoup object from a page that has dozens of images on it. \n",
    "\n",
    "You want to capture the path to each image file on that page (perhaps so that you can download all the images). \n",
    "\n",
    "I would do this in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/thumbnails/park_structures.jpg\n",
      "images/thumbnails/building.jpg\n",
      "images/thumbnails/mosque.jpg\n",
      "images/thumbnails/turrets.jpg\n",
      "images/thumbnails/russia.jpg\n"
     ]
    }
   ],
   "source": [
    "image_list = soup.find_all('img')\n",
    "for image in image_list:\n",
    "    print(image.attrs['src'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
